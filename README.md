# ğŸ™ï¸ Speech Emotion Recognition using Deep Learning

This project is an end-to-end system that classifies human emotions from speech using a trained deep learning model. It leverages audio feature extraction techniques (MFCC, Chroma, Mel Spectrogram, etc.) and a neural network to predict emotions from audio input.

## ğŸ“ Project Structure

```
Emotion-Classification/
â”œâ”€â”€ model/                     # Trained model
â”‚   â””â”€â”€ emotion_model.h5
â”œâ”€â”€ notebook/
â”‚   â””â”€â”€ Emotion_Classification.ipynb
â”œâ”€â”€ scripts/                   # CLI-based testing
â”‚   â””â”€â”€ test_model.py
â”œâ”€â”€ streamlit_app/            # Streamlit web application
â”‚   â””â”€â”€ app.py
â”œâ”€â”€ requirements.txt          # Dependencies
â”œâ”€â”€ README.md                 # This file
â””â”€â”€ demo.mp4                  # Optional demo video (to be added)
```

## ğŸ§  Model Architecture

- Input: Extracted features (MFCC, Chroma, Mel, Contrast, Tonnetz)
- Architecture: Dense Neural Network
  - Dense(512) â†’ ReLU â†’ Dropout(0.3)
  - Dense(256) â†’ ReLU â†’ Dropout(0.3)
  - Dense(128) â†’ ReLU â†’ Dropout(0.3)
  - Output: Softmax over 8 emotion classes
- Trained with: Adam optimizer, early stopping on validation accuracy

### ğŸ¯ Target Emotions
- Neutral
- Calm
- Happy
- Sad
- Angry
- Fearful
- Disgust
- Surprised

---

## ğŸ§ª Evaluation Metrics

| Metric               | Value (Target) |
|----------------------|----------------|
| Overall Accuracy     | > 80% âœ…         |
| F1 Score (Macro Avg) | > 80% âœ…         |
| Per-Class Accuracy   | > 75% âœ…         |
| Confusion Matrix     | âœ… Included     |

All metrics are calculated and visualized in the notebook.

---

## ğŸš€ How to Run

### 1. ğŸ”§ Setup Environment

Install dependencies using:

```bash
pip install -r requirements.txt
```

### 2. ğŸ§ª Run Command-Line Prediction

Test the model on any `.wav` file using:

```bash
python scripts/test_model.py path/to/audio.wav
```

### 3. ğŸŒ Run the Streamlit Web App

```bash
cd streamlit_app
streamlit run app.py
```

Then open: [http://localhost:8501](http://localhost:8501)

### 4. ğŸ“¥ Upload Audio File

Upload a short `.wav` file. The app will return the predicted emotion like:

```
Predicted Emotion: Happy ğŸ¯
```


## ğŸ¤ Credits

- Dataset: RAVDESS (Ryerson Audio-Visual Database of Emotional Speech and Song)
- Libraries: TensorFlow, Librosa, Streamlit, Scikit-learn

---
